{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d46f37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pahadian\\Anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d05a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value\n",
    "seed = random.randint(1, 100000)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62140f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained AlexNet model\n",
    "weights = models.AlexNet_Weights.DEFAULT\n",
    "alexnet = models.alexnet(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7c327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the parameters of the pretrained model\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ac9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the last fully connected layer for binary classification task\n",
    "num_classes = 2  # good or bad\n",
    "num_features = alexnet.classifier[6].in_features\n",
    "alexnet.classifier[6] = torch.nn.Linear(num_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f53394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout to the model\n",
    "dropout_prob = 0.6  # Adjust the dropout probability as needed\n",
    "alexnet.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(dropout_prob),\n",
    "    alexnet.classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c1996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "019454bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb6e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using ImageFolder\n",
    "data_path = 'dataaa/dataset'\n",
    "dataset = ImageFolder(data_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2d54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4077a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_ratio = 0.7  # 70% for training\n",
    "val_ratio = 0.15  # 15% for validation\n",
    "test_ratio = 0.15  # 15% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f7e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = int(val_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6245404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a811f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae224bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "484e27cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for train, validation, and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a6fde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "546a77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66f46fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the device\n",
    "alexnet = alexnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c2e0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(alexnet.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d134a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "mislabel_ratio = 0.32  # % mislabeled images in the training set\n",
    "removal_ratio = 0 # % of mislabeled images to remove each loop\n",
    "original_mislabel_ratio = mislabel_ratio\n",
    "original_total_mislabeled = int(mislabel_ratio * len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01c151e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize running lists to store loss and accuracy values\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "val_loss_values = []\n",
    "val_accuracy_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbfaede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to save loss and accuracy values across all iterations\n",
    "# [[mislabel_ratio, loss_values, accuracy_values, val_loss_values, val_accuracy_values], ...]\n",
    "all_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93dbfcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select mislabel_ratio% indices to mislabel\n",
    "mislabel_indices = random.sample(range(len(train_dataset)), int(mislabel_ratio * len(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a34b0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently 32.00% of images in the training set are mislabeled.\n",
      "Epoch 1/50 - Loss: 0.7284 - Accuracy: 100.00% - Val Loss: 0.2807 - Val Accuracy: 99.62%\n",
      "Epoch 2/50 - Loss: 0.7273 - Accuracy: 100.00% - Val Loss: 0.3029 - Val Accuracy: 99.62%\n",
      "Epoch 3/50 - Loss: 0.7463 - Accuracy: 100.00% - Val Loss: 0.2576 - Val Accuracy: 100.00%\n",
      "Epoch 4/50 - Loss: 0.7417 - Accuracy: 97.90% - Val Loss: 0.3026 - Val Accuracy: 97.90%\n",
      "Epoch 5/50 - Loss: 0.7240 - Accuracy: 100.00% - Val Loss: 0.2813 - Val Accuracy: 99.81%\n",
      "Epoch 6/50 - Loss: 0.7329 - Accuracy: 100.00% - Val Loss: 0.2777 - Val Accuracy: 100.00%\n",
      "Epoch 7/50 - Loss: 0.7166 - Accuracy: 100.00% - Val Loss: 0.2695 - Val Accuracy: 99.81%\n",
      "Epoch 8/50 - Loss: 0.7156 - Accuracy: 100.00% - Val Loss: 0.2680 - Val Accuracy: 100.00%\n",
      "Epoch 9/50 - Loss: 0.7270 - Accuracy: 100.00% - Val Loss: 0.2880 - Val Accuracy: 100.00%\n",
      "Epoch 10/50 - Loss: 0.7219 - Accuracy: 99.81% - Val Loss: 0.2987 - Val Accuracy: 100.00%\n",
      "Epoch 11/50 - Loss: 0.7161 - Accuracy: 100.00% - Val Loss: 0.2712 - Val Accuracy: 100.00%\n",
      "Epoch 12/50 - Loss: 0.7220 - Accuracy: 100.00% - Val Loss: 0.2700 - Val Accuracy: 100.00%\n",
      "Epoch 13/50 - Loss: 0.7244 - Accuracy: 100.00% - Val Loss: 0.2958 - Val Accuracy: 100.00%\n",
      "Epoch 14/50 - Loss: 0.7217 - Accuracy: 100.00% - Val Loss: 0.2790 - Val Accuracy: 100.00%\n",
      "Epoch 15/50 - Loss: 0.7177 - Accuracy: 98.29% - Val Loss: 0.3234 - Val Accuracy: 99.05%\n",
      "Epoch 16/50 - Loss: 0.7333 - Accuracy: 100.00% - Val Loss: 0.2918 - Val Accuracy: 100.00%\n",
      "Epoch 17/50 - Loss: 0.7171 - Accuracy: 100.00% - Val Loss: 0.2891 - Val Accuracy: 100.00%\n",
      "Epoch 18/50 - Loss: 0.7332 - Accuracy: 97.52% - Val Loss: 0.3136 - Val Accuracy: 96.76%\n",
      "Epoch 19/50 - Loss: 0.7231 - Accuracy: 100.00% - Val Loss: 0.2936 - Val Accuracy: 100.00%\n",
      "Epoch 20/50 - Loss: 0.7366 - Accuracy: 100.00% - Val Loss: 0.2545 - Val Accuracy: 100.00%\n",
      "Epoch 21/50 - Loss: 0.7215 - Accuracy: 100.00% - Val Loss: 0.2561 - Val Accuracy: 100.00%\n",
      "Epoch 22/50 - Loss: 0.7099 - Accuracy: 100.00% - Val Loss: 0.2760 - Val Accuracy: 100.00%\n",
      "Epoch 23/50 - Loss: 0.7264 - Accuracy: 100.00% - Val Loss: 0.2514 - Val Accuracy: 100.00%\n",
      "Epoch 24/50 - Loss: 0.7231 - Accuracy: 100.00% - Val Loss: 0.2763 - Val Accuracy: 100.00%\n",
      "Epoch 25/50 - Loss: 0.7185 - Accuracy: 100.00% - Val Loss: 0.2791 - Val Accuracy: 100.00%\n",
      "Epoch 26/50 - Loss: 0.7200 - Accuracy: 100.00% - Val Loss: 0.2592 - Val Accuracy: 100.00%\n",
      "Epoch 27/50 - Loss: 0.7253 - Accuracy: 100.00% - Val Loss: 0.2744 - Val Accuracy: 100.00%\n",
      "Epoch 28/50 - Loss: 0.7162 - Accuracy: 100.00% - Val Loss: 0.2654 - Val Accuracy: 100.00%\n",
      "Epoch 29/50 - Loss: 0.7168 - Accuracy: 99.05% - Val Loss: 0.2918 - Val Accuracy: 99.62%\n",
      "Epoch 30/50 - Loss: 0.7174 - Accuracy: 100.00% - Val Loss: 0.2803 - Val Accuracy: 100.00%\n",
      "Epoch 31/50 - Loss: 0.7351 - Accuracy: 100.00% - Val Loss: 0.2741 - Val Accuracy: 100.00%\n",
      "Epoch 32/50 - Loss: 0.7304 - Accuracy: 100.00% - Val Loss: 0.2490 - Val Accuracy: 100.00%\n",
      "Epoch 33/50 - Loss: 0.7211 - Accuracy: 100.00% - Val Loss: 0.2770 - Val Accuracy: 100.00%\n",
      "Epoch 34/50 - Loss: 0.7153 - Accuracy: 100.00% - Val Loss: 0.2730 - Val Accuracy: 100.00%\n",
      "Epoch 35/50 - Loss: 0.7139 - Accuracy: 99.43% - Val Loss: 0.2785 - Val Accuracy: 99.62%\n",
      "Epoch 36/50 - Loss: 0.7336 - Accuracy: 100.00% - Val Loss: 0.2867 - Val Accuracy: 100.00%\n",
      "Epoch 37/50 - Loss: 0.7224 - Accuracy: 100.00% - Val Loss: 0.2910 - Val Accuracy: 100.00%\n",
      "Epoch 38/50 - Loss: 0.7117 - Accuracy: 99.81% - Val Loss: 0.2678 - Val Accuracy: 100.00%\n",
      "Epoch 39/50 - Loss: 0.7386 - Accuracy: 100.00% - Val Loss: 0.2694 - Val Accuracy: 100.00%\n",
      "Epoch 40/50 - Loss: 0.7223 - Accuracy: 100.00% - Val Loss: 0.2786 - Val Accuracy: 100.00%\n",
      "Epoch 41/50 - Loss: 0.7184 - Accuracy: 100.00% - Val Loss: 0.2578 - Val Accuracy: 100.00%\n",
      "Epoch 42/50 - Loss: 0.7361 - Accuracy: 91.81% - Val Loss: 0.3581 - Val Accuracy: 95.43%\n",
      "Epoch 43/50 - Loss: 0.7132 - Accuracy: 100.00% - Val Loss: 0.2684 - Val Accuracy: 100.00%\n",
      "Epoch 44/50 - Loss: 0.7153 - Accuracy: 99.81% - Val Loss: 0.2652 - Val Accuracy: 100.00%\n",
      "Epoch 45/50 - Loss: 0.7294 - Accuracy: 100.00% - Val Loss: 0.2960 - Val Accuracy: 100.00%\n",
      "Epoch 46/50 - Loss: 0.7212 - Accuracy: 100.00% - Val Loss: 0.2590 - Val Accuracy: 100.00%\n",
      "Epoch 47/50 - Loss: 0.7229 - Accuracy: 100.00% - Val Loss: 0.2757 - Val Accuracy: 100.00%\n",
      "Epoch 48/50 - Loss: 0.7093 - Accuracy: 100.00% - Val Loss: 0.2868 - Val Accuracy: 100.00%\n",
      "Epoch 49/50 - Loss: 0.7193 - Accuracy: 100.00% - Val Loss: 0.2678 - Val Accuracy: 100.00%\n",
      "Epoch 50/50 - Loss: 0.7086 - Accuracy: 100.00% - Val Loss: 0.2666 - Val Accuracy: 100.00%\n",
      "Corrected 20% of mislabeled images. Remaining mislabel ratio: 32.00%\n"
     ]
    }
   ],
   "source": [
    "for loop in range(1):\n",
    "    print(f'Currently {mislabel_ratio * 100:.2f}% of images in the training set are mislabeled.')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Training phase\n",
    "        alexnet.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "\n",
    "            if i in mislabel_indices:\n",
    "                # Change the label to the opposite label\n",
    "                mislabeled_labels = 1 - labels\n",
    "                labels = mislabeled_labels.to(device)\n",
    "            else:\n",
    "                labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = alexnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Evaluation phase - Training Set\n",
    "        alexnet.eval()\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = alexnet(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total_predictions += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # Evaluation phase - Validation set\n",
    "        alexnet.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = alexnet(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                val_total_predictions += labels.size(0)\n",
    "                val_correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate the loss and accuracy for each epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "\n",
    "        # Calculate validation loss and accuracy for the epoch\n",
    "        val_epoch_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct_predictions / val_total_predictions\n",
    "\n",
    "        # Append loss and accuracy values to the lists\n",
    "        loss_values.append(epoch_loss)\n",
    "        accuracy_values.append(accuracy)\n",
    "        val_loss_values.append(val_epoch_loss)\n",
    "        val_accuracy_values.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {accuracy * 100:.2f}% - '\n",
    "              f'Val Loss: {val_epoch_loss:.4f} - Val Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "    # Save values\n",
    "    all_values.append([mislabel_ratio, loss_values, accuracy_values, val_loss_values, val_accuracy_values])\n",
    "\n",
    "    # Reset\n",
    "    loss_values = []\n",
    "    accuracy_values = []\n",
    "    val_loss_values = []\n",
    "    val_accuracy_values = []\n",
    "\n",
    "    # Remove a portion of mislabeled indices\n",
    "    if mislabel_ratio > 0:\n",
    "        num_indices_to_remove = int(removal_ratio * original_total_mislabeled)\n",
    "        mislabel_indices_to_remove = random.sample(mislabel_indices, num_indices_to_remove)\n",
    "        mislabel_indices = [i for i in mislabel_indices if i not in mislabel_indices_to_remove]\n",
    "        mislabel_ratio -= (removal_ratio * original_mislabel_ratio)\n",
    "        if mislabel_ratio < 0:\n",
    "            mislabel_ratio = 0\n",
    "\n",
    "    print(f'Corrected 20% of mislabeled images. Remaining mislabel ratio: {mislabel_ratio * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5729b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all_values to a file\n",
    "with open(f'outputs_{seed}.pkl', 'wb') as file:\n",
    "    pickle.dump(all_values, file)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
